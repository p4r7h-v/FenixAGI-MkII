<h1>Title: Streamlining Research and Assisting with FenixAGI Mk1</h1>
<h2>Introduction</h2>
<p>FenixAGI Mk1 is an advanced AI assistant designed to revolutionize research and assistance tasks. Built on OpenAI's
    GPT-16k 3.5-turbo language model, FenixAGI Mk1 offers a range of functions that can aid researchers and help
    streamline their workflows. This Substack post provides a detailed overview of the <code>fenix.py</code> file,
    showcasing its structure, functionality, and usage instructions.</p>
<h2>File Structure</h2>
<p>The <code>fenix.py</code> file acts as the core component of FenixAGI Mk1, powering its research-oriented functions
    and assistance capabilities. Here's a breakdown of its components:</p>
<h3>Libraries and Global Variables</h3>
<p>The <code>fenix.py</code> file imports essential libraries such as <code>openai</code>, <code>json</code>,
    <code>os</code>, <code>pandas</code>, and <code>termcolor</code>. Additionally, it initializes critical global
    variables including the approved functions list, colors dictionary, and FenixState class, laying the foundation for
    FenixAGI Mk1's operations.</p>
<h3>FenixState Class</h3>
<p>The <code>FenixState</code> class assumes the responsibility of capturing and retaining the state of the FenixAGI
    assistant. This includes preserving the conversation history, instructions, executed function calls, display
    response settings, operational mode, and approved functions, all of which allow for seamless interactions and
    personalized experiences.</p>
<h3>Helper Functions</h3>
<p>To enhance its research capabilities and provide effective assistance, FenixAGI Mk1 incorporates several helper
    functions. These include <code>fenix_help()</code> for providing guidance, <code>save_fenix()</code> for saving the
    current state, <code>derezz_fnix()</code> for resetting the assistant, <code>ask_user()</code> for collecting user
    input, and <code>tell_user()</code> for delivering informative messages. These functions contribute to the
    efficiency of the assistant and enhance the overall user experience.</p>
<h3>Main Conversation Loop</h3>
<p>The <code>run_conversation()</code> function serves as the entry point for FenixAGI Mk1's research and assistance
    capabilities. This function processes user input and utilizes the GPT-3.5-turbo language model to generate
    responses. If a function call is detected in the response, FenixAGI Mk1 executes the corresponding function based on
    the mode (manual or automatic) and user approval. The conversation history is updated with both user input and
    assistant responses, ensuring a continuous and interactive experience.</p>
<h2>Utilization Instructions</h2>
<p>To utilize FenixAGI Mk1 for research and assistance tasks, follow these instructions:</p>
<ol>
    <li><strong>Setting up API Keys</strong>: Obtain the necessary API keys before using FenixAGI Mk1:</li>
    <li>BING_SEARCH_KEY: Access this key from the Bing Search API portal (<a
            href="https://portal.azure.com/#">https://portal.azure.com/</a>)</li>
    <li>
        <p>OPENAI_API_KEY: Obtain this key for the GPT-3.5-turbo-16k model by signing up at <a
                href="https://platform.openai.com/signup">https://platform.openai.com/signup</a></p>
    </li>
    <li>
        <p><strong>Running FenixAGI Mk1</strong>: Execute the <code>run_conversation()</code> function within the
            <code>fenix.py</code> file to initiate FenixAGI Mk1 and start the conversation loop.</p>
    </li>
    <li>
        <p><strong>Interacting with FenixAGI Mk1</strong>: Utilize the command line interface to communicate with
            FenixAGI Mk1. Input your messages after the <code>&gt;</code> prompt, and FenixAGI Mk1 will respond
            accordingly.</p>
    </li>
    <li>
        <p>Special commands: FenixAGI Mk1 recognizes commands such as 'exit', 'quit', '~', '1', and '2' for various
            operations. Utilize these commands to control FenixAGI Mk1's behavior and settings during the conversation.
        </p>
    </li>
    <li>
        <p><strong>Expanding Functionality</strong>: FenixAGI Mk1 supports extensibility. Expand its capabilities by
            adding new functions to the <code>approved_functions</code> list and corresponding entries to the
            <code>function_descriptions</code> list. This enables customization and the incorporation of additional
            research and assistance functionalities.</p>
    </li>
    <li>
        <p><strong>Saving and Restoring State</strong>: FenixAGI Mk1 automatically saves its state to the
            <code>fenix_state.json</code> file. Upon relaunch, FenixAGI Mk1 checks for this file and restores the
            previous state if available. You can manually reset FenixAGI Mk1 and the state by entering '0' as your user
            input.</p>
    </li>
</ol>
<h2>Conclusion</h2>
<p>FenixAGI Mk1, powered by OpenAI's GPT-3.5-turbo language model, is a powerful AI assistant designed to streamline
    research and provide assistance. With its research-oriented functions, personalization capabilities, and
    extensibility, FenixAGI Mk1 empowers researchers and enhances their workflow. Fork the FenixAGI Mk1 repository on
    Replit and experience the transformative potential it holds.</p>
<p>You can fork and run Fenix locally or on Replit at <a
        href="https://replit.com/@p4r7h/FenixAGI-Mk-1-Function-Caller?v=1">https://replit.com/@p4r7h/FenixAGI-Mk-1-Function-Caller?v=1</a>
</p>
<p>For any inquiries, feedback, or collaboration opportunities, feel free to reach out to Parth Patil, the creator of
    FenixAGI Mk1, on LinkedIn at <a
        href="https://www.linkedin.com/in/parthspatil/">https://www.linkedin.com/in/parthspatil/</a>.</p>