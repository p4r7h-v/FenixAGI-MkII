{"conversation": [{"role": "system", "content": "Fenix State Created."}, {"role": "user", "content": "read fenix.py and write a readme"}, {"role": "system", "content": "Function Response: Here are the contents of fenix.py:\n'''\nIntroducing FenixAGI, an advanced AI assistant designed to revolutionize project management. Powered by Open A.I.'s GPT-16k 3.5-turbo language model, Fenix is a versatile companion that assists users in various tasks.\n'''\n\nimport openai\nimport json\nimport os\nimport pandas as pd\nfrom termcolor import colored\nfrom functions import *\nfrom function_descriptions import function_descriptions\nimport pyttsx3\nimport tenacity\nfrom elevenlabs import voices, generate, set_api_key\nimport soundfile\nimport simpleaudio as sa\nimport re\n\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nset_api_key(os.environ['xi-api-key'])\n\n\napproved_functions = [\n    \"search_codebase\",\n    \"bing_search_save\",\n    \"scrape_website\",\n    \"save_fenix\",\n    \"read_file\",\n    \"write_file\",\n    \"delete_file\",\n    \"create_directory\",\n    \"ask_user_for_additional_information\",\n    \"create_code_search_csv\",\n    \"count_tokens_in_string\",\n    \"count_tokens_in_file\",\n    \"create_markdown_file\",\n    \"fenix_help\",\n    \"move_file\",\n    \"list_files_in_directory\",\n    \"suggest_function_chain\",\n    \"visualize_data_3d\",\n]\n\nbase_instructions = \"Fenix A.G.I. Mark-II is an advanced AI assistant built by a guy named Parth. Fenix is an AI agent built on top of the Open A.I. GPT language models. Fenix can execute the following functions:\" + str(approved_functions) + \\\n    \"Fenix can also learn from the user's feedback and revise its instructions to improve its performance over time. Designed to be extended and personalized, Fenix is a powerful tool for any developer, researcher, or student.\"\n\nCOLORS = {\n    'launch': 'cyan',\n    'function_call': 'cyan',\n    'function_info': 'green',\n    'important': 'red',\n    'query': 'green',\n    'response': 'blue',\n    # Add more as necessary...\n}\n\n# Check if voices are available otherwise use pyttsx3\ntry:    \n    all_voices = voices()\n    voice_id = next(\n        (voice.voice_id for voice in all_voices\n        if voice.name == 'Parth TTS'), None)\n    premium_voice_enabled = True\nexcept:\n    voice_id = None\n    premium_voice_enabled = False\n\n\n\nclass FenixState:\n\n    def __init__(self,\n                 conversation=[],\n                 instructions=\"\",\n                 display_response=False,\n                 mode=\"auto\",\n                 approved_functions=approved_functions,\n                 voice_mode=None):\n        self.conversation = conversation\n        self.instructions = instructions\n        self.display_response = display_response\n        self.mode = mode\n        self.approved_functions = approved_functions\n        self.voice_mode = voice_mode\n\n\ndef play_audio(file_path):\n    wave_obj = sa.WaveObject.from_wave_file(file_path)\n    play_obj = wave_obj.play()\n    play_obj.wait_done()\n\n\ndef fenix_help(help_query):\n    help_text = '''\nFenix is an advanced AI assistant made by Parth: https://www.linkedin.com/in/parthspatil/ https://twitter.com/htrapvader \nFor more wacky LLM projects: https://replit.com/@p4r7h.\n  Restoring Fenix State\n  At the start of a session, the function checks if a saved state of the Fenix AI assistant exists. If it does, the state is loaded and the session continues from where it left off last time. If not, a new state is initialized.\n  User Input\n  The function continuously prompts the user for input and processes it accordingly.\n  Special Commands\n  There are several special commands the user can input to control the behavior of Fenix:\n  'exit' or 'quit': Terminates the session and saves the current state of Fenix.\n  'v': Toggles between different voice_modes for Fenix. Fenix can use the default voice, a voice clone of the creator (Parth), or no voice at all. Feel free to add your own voice clones to the list of available voices.\n  'a': Toggles between manual and automatic mode. In manual mode, Fenix will ask for approval before executing a function. In automatic mode, approved functions are executed automatically.\n  'd': Toggles whether the assistant's responses should be displayed or not.\n  'r': Resets Fenix to a default state, clearing the conversation history and meta instructions.\n  AI Response Generation\n  The user's input (and the entire conversation history) is fed into an instance of the GPT-3.5-turbo model, which generates the assistant's response. If the response includes a function call, the function is executed if it is approved and the mode is either manual and approved by user, or automatic. The result of the function call can optionally be displayed to the user, depending on the current settings.\n  Extending Functionality\n  New functionality can be added to Fenix by adding new functions to the approved_functions list and corresponding entries to the function_descriptions list.\n  Error Handling\n  Errors during the execution of a function are handled by returning an error message to the user and not executing the function. Unrecognized user inputs in response to a function call prompt are treated as 'no' responses.\n  Future Development\n  Currently, the conversation history used to generate responses is limited by the maximum context length of the GPT-3.5-turbo model. Future versions of the run_conversation() function may implement more sophisticated methods for managing long conversation histories.'''\n    help_text += \"\\n\\nFenix is also capable of executing a wide range of functions, and visualizing information, these don't have explicit keystrokes. Here are the available functions for Fenix: \"\n    help_text += \"\\n\".join(\n        [f\"\\n {function}\" for i, function in enumerate(approved_functions)])\n    return help_text\n    help_text += \"\\n\\nFenix is also capable of executing a wide range of functions, these don't have explicit keystrokes. Here are the available functions for Fenix: \"\n    help_text += \"\\n\".join(\n        [f\"\\n {function}\" for i, function in enumerate(approved_functions)])\n    return help_text\n\n\ndef critique_and_revise_instructions(instructions, conversation_history, approved_functions):\n    chat_log = '\\n'.join([\n        f\"{msg['role'].capitalize()}: {msg['content']}\"\n        for msg in conversation_history\n    ])\n\n    meta_prompt = f\"\"\"The Assistant has just had the following interactions with a User. Please critique the Assistant's performance and revise the Instructions based on the interactions.\n\n    ####\n    Approved Functions (the Assistant can use these functions):\n    {approved_functions}\n    Chat Log:\n    {chat_log}\n\n    ####\n\n    First, critique the Assistant's performance: What could have been done better? \n    Then, revise the Instructions to improve the Assistant's responses in the future. \n    The new Instructions should help the Assistant satisfy the user's request in fewer interactions. \n\n    Start your critique with \"Critique: ...\" and your revised instructions for the assistant with \"New Instructions:\".\n\n    \"\"\"\n\n    meta_response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-16k-0613\",\n                                                 messages=[{\n                                                     \"role\": \"user\",\n                                                     \"content\": meta_prompt\n                                                 }])\n    tell_user(\n        \"Analyzing conversation history and learning from your feedback...\",\n        \"yellow\",fenix_state.voice_mode)\n    print(colored(\"Meta Prompt: \" + meta_prompt, \"cyan\"))\n    print(\"Token count is:\", count_tokens_in_string(meta_prompt))\n    meta_text = meta_response['choices'][0]['message']['content']\n    # count_tokens_in_string(meta_text)\n    print(\n        colored(\n            \"Meta Critique: \" +\n            meta_text.split(\"Critique: \")[1].split(\n                \"New Instructions:\")[0].strip(),\n            \"yellow\"))\n    try:\n        new_instructions = meta_text.split(\"New Instructions:\")[1].strip()\n        print(colored(\"New Instructions: \" + new_instructions, \"cyan\"))\n    except IndexError:\n        print(\"No new instructions found in AI output.\")\n        return \"\"\n\n    return new_instructions\n\n\ndef save_fenix(filename=\"fenix_state.json\"):\n    global fenix_state  # Access the global instance\n    with open(\"fenix_state.json\", 'w') as f:\n        json.dump(fenix_state.__dict__, f)\n        return \"Fenix State Saved.\"\n\n\ndef rez_fenix(filename=\"fenix_state.json\"):\n    try:\n        with open('fenix_state.json', 'r') as f:\n            if f.read():\n                # Move the read cursor back to the start of the file\n                f.seek(0)\n                data = json.load(f)\n                fenix_state = FenixState(**data)  # Load data if there is any\n            else:\n                print(\"The file is empty.\")\n                fenix_state = FenixState()  # Create a new state\n    except FileNotFoundError:\n        fenix_state = FenixState()  # Create a new state if no data\n    return fenix_state\n\n\ndef derez_fenix(filename=\"fenix_state.json\"):\n    # Delete the fenix_state.json file\n    if os.path.exists(\"fenix_state.json\"):\n        os.remove(\"fenix_state.json\")\n        return \"Fenix State Derezzed.\"\n\n\ndef stringify_conversation(conversation):\n    return ' '.join([str(msg) for msg in conversation])\n\n\ndef ask_user(question, color='purple'):\n    return input(colored(f\"\\n{question}\", color))\n\n\ndef tell_user(message, color='blue',voice_mode=None):\n    print(colored(message, color))\n    voice_message(message, voice_mode)\n\n\ndef truncate_conversation(conversation, user_input=\"\", function_response=\"\"):\n    MAX_TOKENS = 15000\n\n    if count_tokens_in_string(stringify_conversation(conversation)) > MAX_TOKENS:\n        # Remove oldest messages until we have room for new ones\n        while count_tokens_in_string(stringify_conversation(conversation)) + count_tokens_in_string(user_input) + count_tokens_in_string(str(function_response)) > MAX_TOKENS:\n            # print(\"Dropping: \" + str(conversation[2]))\n            removed_message = conversation.pop(2)\n            removed_message = conversation.pop(3)\n            # print(f\"Removing message due to token limit: {removed_message}\")\n    return conversation\n\n\ndef strip_string(input_string):\n    # Keep only alphanumeric characters, dashes, and spaces\n    cleaned_string = re.sub(r'[^a-zA-Z0-9- ]+', '', input_string)\n\n    pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n\n    # Replace matches with an empty string\n    cleaned_string = re.sub(pattern, '', cleaned_string)\n    \n    # Remove code blocks\n    cleaned_string = re.sub(r'```.*?```', '', cleaned_string, flags=re.DOTALL)\n \n    return cleaned_string.strip()\n\n\n\n@tenacity.retry(stop=tenacity.stop_after_attempt(5), wait=tenacity.wait_fixed(2))\ndef voice_message(message, voice_mode=None):\n    if (voice_mode is None):\n        return\n    else:\n        voice_prompt = base_instructions + \"You are Fenix A.G.I. Mark-II's voice. The 'eleven_monolingual_v1' voice is a 2nd generation voice clone (clone of a voice clone of the creator, 'a guy named Parth'). You present given text as if you are Fenix. If the text is a function response, describe it extremely briefly. If it says there's a visualization, assume there's a visualization. sYour response is short and to the point. If you see a list, just describe the list at a high level. Use dashes '-' for natural pauses and ellipses '...' for more of a hesitant pause. You always respond in first person as Fenix, replacing references to Fenix with 'I'. Your response is short and to the point and around 3 sentences in length. Any mention of 'OpenAI' can be replaced with 'Open A.I.'. Here is the text you will present: \" + \\\n            message\n        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-16k-0613\",\n                                                messages=[\n                                                    {\n                                                        \"role\": \"system\",\n                                                        \"content\": voice_prompt,\n                                                    }],\n                                                max_tokens=500,\n                                                temperature=1,\n                                                top_p=1.0,\n                                                )\n        voice_response = response['choices'][0]['message']['content']\n\n\n        stripped_voice_response = strip_string(voice_response)\n        if (voice_mode == \"eleven_monolingual_v1\"):\n            audio = generate(\n                text=stripped_voice_response,\n                voice=voice_id,\n                model=\"eleven_monolingual_v1\"\n            )\n\n            # Save audio to a file\n            file_path = 'audio.wav'\n            # print(file_path)\n\n            with open(file_path, \"wb\") as file:\n                file.write(audio)\n\n            # Read and rewrite the file with soundfile\n            data, samplerate = soundfile.read(file_path)\n            soundfile.write(file_path, data, samplerate)\n\n            # Play audio\n            play_audio(file_path)\n        \n        elif (voice_mode == \"pyttsx3\"):\n            # use the pyttsx3 library to play back the response\n            engine = pyttsx3.init()\n            engine.say(stripped_voice_response)\n            engine.runAndWait()\n\n\n@tenacity.retry(stop=tenacity.stop_after_attempt(5), wait=tenacity.wait_fixed(2))\ndef get_base_streaming_response(model, messages):\n    # try to get a response from the model if it fails, drop the 3rd oldest message and try again\n    try:\n        # use the openai api to generate a response\n        response = openai.ChatCompletion.create(\n            model=model,\n            messages=messages,\n            stream=True,\n        )\n    except Exception as e:\n        print(e)\n        messages.pop(2)\n        response = openai.ChatCompletion.create(\n            model=model,\n            messages=messages,\n            stream=True,\n        )\n    responses = ''\n    # Process each chunk\n    for chunk in response:\n        if \"role\" in chunk[\"choices\"][0][\"delta\"]:\n            continue\n        elif \"content\" in chunk[\"choices\"][0][\"delta\"]:\n            r_text = chunk[\"choices\"][0][\"delta\"][\"content\"]\n            responses += r_text\n            print(r_text, end='', flush=True)\n    assistant_message = responses\n    messages.append({\n        \"role\": \"assistant\",\n        \"content\": assistant_message\n    })\n    return messages, assistant_message\n\n\n@tenacity.retry(stop=tenacity.stop_after_attempt(5), wait=tenacity.wait_fixed(2))\ndef get_function_calling_response(model, messages, functions, function_call):\n    # try to get a response from the model if it fails, drop the 3rd oldest message and try again\n    try:\n        # use the openai api to generate a response\n        response = openai.ChatCompletion.create(\n            model=model,\n            messages=messages,\n            functions=functions,\n            function_call=function_call,\n        )\n    except Exception as e:\n        print(e)\n        messages.pop(2)\n        response = openai.ChatCompletion.create(\n            model=model,\n            messages=messages,\n            functions=functions,\n            function_call=function_call,\n        )\n    return response\n\n\ndef run_conversation():\n    global fenix_state\n    # Check if the state file exists\n    if os.path.exists(\"fenix_state.json\"):\n        fenix_state = rez_fenix()\n        conversation = fenix_state.conversation\n        conversation.append(\n            {\"role\": \"system\", \"content\": \"Fenix State Rezzed.\"})\n    else:\n        fenix_state = FenixState(display_response=True,\n                                 mode=\"auto\",\n                                 approved_functions=approved_functions,\n                                 voice_mode=\"pyttsx3\")\n        conversation = fenix_state.conversation\n        conversation.append(\n            {\"role\": \"system\", \"content\": \"Fenix State Created.\"})\n\n    fenix_state.instructions = base_instructions\n    tell_user(\"Agent Fenix is Online.\", COLORS['launch'],fenix_state.voice_mode)\n\n    tell_user(\"\"\"There are several special keyboard commands the user can input to control the behavior of Fenix. Here are the special keyboard commands:\n\n  'v': Toggles between different voice_modes for Fenix. Fenix can use the default voice, a voice clone of the creator (Parth), or no voice at all. Feel free to add your own voice clones to the list of available voices.\n  'a': Toggles between manual and automatic mode. In manual mode, Fenix will ask for approval before executing a function. In automatic mode, approved functions are executed automatically.\n  'd': Toggles whether the assistant's responses should be displayed or not.\n  'r': Resets Fenix to a default state, clearing the conversation history and meta instructions.\n  'exit' or 'quit': Terminates the session and saves the current state of Fenix.\"\"\",\n              COLORS['important'],None)\n\n\n    while True:\n        user_input = ask_user(\"> \", COLORS['query'])\n        if user_input.lower() in [\"exit\", \"quit\"]:\n            tell_user(\"Exiting Fenix.\", COLORS['important'],fenix_state.voice)\n            conversation.append(\n                {\"role\": \"system\", \"content\": \"Exiting Fenix.\"})\n            save_fenix()\n            conversation.append({\"role\": \"system\", \"content\": \"State saved.\"})\n            break\n\n        elif user_input.lower() in [\"r\"]:\n            # Update the meta instructions\n            user_input = \"Update the meta instructions.\"\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            fenix_state.instructions = critique_and_revise_instructions(fenix_state.instructions,\n                                                                        conversation, approved_functions)\n            conversation.append({\n                \"role\": \"system\",\n                \"content\": \"Meta instructions updated.\"\n            })\n            save_fenix()\n            conversation.append({\"role\": \"system\", \"content\": \"State saved.\"})\n\n        elif user_input.lower() == \"a\":\n            # Toggle automatic function calling mode\n            user_input = \"Toggle automatic function calling mode.\"\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            if (fenix_state.mode == \"manual\"):\n                fenix_state.mode = \"auto\"\n                tell_user(\"Fenix will now execute approved functions automatically.\",\n                          COLORS['important'],fenix_state.voice_mode)\n                conversation.append({\n                    \"role\": \"system\",\n                    \"content\": \"Fenix is now in automatic mode.\"\n                })\n                conversation.append({\n                    \"role\":\n                    \"system\",\n                    \"content\":\n                    \"Fenix will now execute approved functions automatically.\"\n                })\n            elif (fenix_state.mode == \"auto\"):\n                fenix_state.mode = \"manual\"\n                tell_user(\n                    \"Fenix will now ask for approval before executing a function.\",\n                    COLORS['important'],fenix_state.voice_mode)\n                conversation.append({\n                    \"role\": \"system\",\n                    \"content\": \"Fenix is now in manual mode.\"\n                })\n                conversation.append({\n                    \"role\":\n                    \"system\",\n                    \"content\":\n                    \"Fenix will now ask for approval before executing a function.\"\n                })\n        elif user_input == \"d\":\n            # Toggle display response\n            user_input = \"Toggle display response.\"\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            fenix_state.display_response = not fenix_state.display_response\n            tell_user(\n                f\"Display Function Response is now set to {fenix_state.display_response}.\",\n                COLORS['important'],fenix_state.voice_mode)\n\n            conversation.append({\n                \"role\":\n                \"system\",\n                \"content\":\n                f\"Display Function Response is now set to {fenix_state.display_response}.\"\n            })\n\n        elif user_input.lower() == \"v\":\n            # Toggle voice\n            user_input = \"Toggle voice.\"\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n\n            if fenix_state.voice_mode == \"pyttsx3\":\n                if premium_voice_enabled:\n                    #switch to eleven labs\n                    fenix_state.voice_mode = \"eleven_monolingual_v1\"\n                else:\n                    # switch to None\n                    fenix_state.voice_mode = None\n            elif fenix_state.voice_mode == \"eleven_monolingual_v1\":\n                # switch to None\n                fenix_state.voice_mode = None\n            elif fenix_state.voice_mode == None:\n                # switch to pyttsx3\n                fenix_state.voice_mode = \"pyttsx3\"\n            conversation.append({\n                \"role\": \"system\",\n                \"content\": \"Voice is now set to \" + str(fenix_state.voice_mode)\n            })\n            tell_user(\n                f\"Voice is now set to {fenix_state.voice_mode}.\",\n                COLORS['important'],fenix_state.voice_mode)\n\n        elif user_input.lower() == \"r\":\n            # update meta instructions and derez fenix\n            temp_instructions = critique_and_revise_instructions(fenix_state.instructions,\n                                                                 conversation, approved_functions)\n            # Derez Fenix\n            user_input = \"Derez Fenix.\"\n            conversation.clear()  # Clear the conversation list\n            fenix_state.conversation.clear()  # Clear the conversation in FenixState\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n\n            derez_fenix()\n\n            fenix_state = FenixState(display_response=False,\n                                     instructions=base_instructions+\" \" + temp_instructions,\n                                     mode=\"auto\",\n                                     approved_functions=approved_functions)\n            tell_user(\"Meta Instructions updated and conversation history reset.\",\n                      COLORS['important'],fenix_state.voice_mode)\n            tell_user(\"I have appended the following instructions to my base instructions: \" + temp_instructions,\n                      COLORS['important'],fenix_state.voice_mode)\n            conversation = fenix_state.conversation\n            conversation.append({\n                \"role\": \"system\",\n                \"content\": \"New Fenix State Created.\"\n            })\n\n        else:\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            response = get_function_calling_response(\n                model=\"gpt-3.5-turbo-16k-0613\",\n                messages=conversation,\n                functions=function_descriptions,\n                function_call=\"auto\",\n            )\n\n            message = response[\"choices\"][0][\"message\"]\n            if message.get(\"function_call\"):\n                print(colored((\"Function Call:\" + str(message.get('function_call'))\n                               ), \"cyan\"))\n                function_name = message[\"function_call\"][\"name\"]\n                if function_name in approved_functions:\n                    try:\n                        args = json.loads(message[\"function_call\"][\"arguments\"])\n                    except json.JSONDecodeError as e:\n                        print(f\"Failed to decode JSON: {e}\")\n                    else:\n                        current_function_call = (function_name, args)\n\n                    if fenix_state.mode == \"manual\":\n                        user_input = ask_user(\"Do you want to run the function? (y/n)\",\n                                              COLORS['query'])\n                        if user_input.lower() in [\"y\", \"yes\"]:\n                            try:\n                                function_response = eval(function_name)(**args)\n                            except Exception as e:\n                                function_response = f\"Error: {str(e)}\"\n\n                        elif user_input.lower() in [\"n\", \"no\", \"exit\", \"quit\"]:\n                            tell_user(\n                                \"Function Call: Not executing function\", COLORS['important'],fenix_state.voice_mode)\n                            assistant_message = \"Function execution skipped by user.\"\n                            conversation.append({\n                                \"role\": \"assistant\",\n                                \"content\": assistant_message\n                            })\n                            function_response = None\n                        else:\n                            tell_user(\n                                \"Unrecognized input. Default action is not to execute the function.\",\n                                COLORS['important'],fenix_state.voice_mode)\n                            assistant_message = \"Function execution skipped due to unrecognized input.\"\n                            conversation.append({\n                                \"role\": \"assistant\",\n                                \"content\": assistant_message\n                            })\n                            function_response = None\n                    elif fenix_state.mode == \"auto\":\n                        try:\n                            function_response = eval(function_name)(**args)\n                        except Exception as e:\n                            function_response = f\"Error: {str(e)}\"\n\n                    if function_response is not None:\n                        print(\n                            colored(\"Function Response: \"+function_response, COLORS['response']))\n                        \n                        function_content = {\n                            \"role\": \"function\",\n                            \"name\": function_name,\n                            \"content\": str(function_response),\n                        }\n\n                        conversation.append({\n                            \"role\": \"system\",\n                            \"content\": \"Function Response: \" + str(function_response)\n                        })\n                        print(\"Conversation length (tokens): \" +\n                              str(count_tokens_in_string(stringify_conversation(conversation))))\n                        conversation = truncate_conversation(\n                            conversation, user_input, function_response)\n\n                        conversation, assistant_message = get_base_streaming_response(\n                            model=\"gpt-3.5-turbo-16k-0613\",\n                            messages=conversation + [\n                                {\n                                    \"role\": \"user\",\n                                    \"content\": user_input\n                                },\n                                function_content,\n                            ],\n                        )\n\n                        conversation.append({\n                            \"role\": \"assistant\",\n                            \"content\": assistant_message\n                        })\n\n                else:\n                    tell_user(\"Sorry, I don't have access to that function.\",\n                              COLORS['important'],fenix_state.voice_mode)\n                    assistant_message = \"Function execution skipped by assistant.\"\n                    conversation.append({\n                        \"role\": \"assistant\",\n                        \"content\": assistant_message\n                    })\n\n            else:\n                conversation = truncate_conversation(conversation, user_input)\n                conversation, assistant_message = get_base_streaming_response(\n                    model=\"gpt-3.5-turbo-16k\",\n                    messages=[\n                        {\n                            \"role\": \"system\",\n                            \"content\": base_instructions+\"Here are the functions Fenix has access to:\" + str(approved_functions) + \"If the user doesn't have a question, predict 3 possible follow-ups from the user, and return them as a list of options.\",\n                        }]+conversation,\n                )\n            #print(\"Voice is: \", fenix_state.voice_mode)\n            voice_message(assistant_message, fenix_state.voice_mode)\n\n        # print(\"\\nConversation length (tokens): \" + str(count_tokens_in_string(stringify_conversation(conversation))))\n        save_fenix()\n\n\nrun_conversation()\n"}, {"role": "system", "content": "Fenix State Rezzed."}, {"role": "user", "content": "all the api keys are os.getenv, write readme instructions so a user knows to set up bing, openai, and elevenlabs api keys"}, {"role": "system", "content": "Function Response: Successfully created file: ./content/README.md"}, {"role": "system", "content": "Fenix State Rezzed."}, {"role": "user", "content": "Toggle voice."}, {"role": "system", "content": "Voice is now set to eleven_monolingual_v1"}, {"role": "user", "content": "how do your api keys work"}, {"role": "system", "content": "Fenix State Rezzed."}, {"role": "user", "content": "search the web for the probability of agi"}, {"role": "system", "content": "Function Response: Error: 401 Client Error: PermissionDenied for url: https://api.bing.microsoft.com/v7.0/search?q=probability+of+AGI&count=50&offset=0&freshness=Month"}, {"role": "system", "content": "Fenix State Rezzed."}, {"role": "user", "content": "search the web for montell2099"}, {"role": "system", "content": "Function Response: Error: Invalid Bing Search Key"}, {"role": "system", "content": "Fenix State Rezzed."}, {"role": "user", "content": "who are you?"}], "instructions": "Fenix A.G.I. Mark-II is an advanced AI assistant built by a guy named Parth. Fenix is an AI agent built on top of the Open A.I. GPT language models. Fenix can execute the following functions:['search_codebase', 'bing_search_save', 'scrape_website', 'save_fenix', 'read_file', 'write_file', 'delete_file', 'create_directory', 'ask_user_for_additional_information', 'create_code_search_csv', 'count_tokens_in_string', 'count_tokens_in_file', 'create_markdown_file', 'fenix_help', 'move_file', 'list_files_in_directory', 'suggest_function_chain', 'visualize_data_3d']Fenix can also learn from the user's feedback and revise its instructions to improve its performance over time. Designed to be extended and personalized, Fenix is a powerful tool for any developer, researcher, or student.", "display_response": true, "mode": "auto", "approved_functions": ["search_codebase", "bing_search_save", "scrape_website", "save_fenix", "read_file", "write_file", "delete_file", "create_directory", "ask_user_for_additional_information", "create_code_search_csv", "count_tokens_in_string", "count_tokens_in_file", "create_markdown_file", "fenix_help", "move_file", "list_files_in_directory", "suggest_function_chain", "visualize_data_3d"], "voice_mode": "eleven_monolingual_v1"}